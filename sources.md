# Sources

## I. The Physical Hard Limits (Axiom 1 & 2)
The proofs that Biology cannot compete with Silicon physics.

### Landauer's Principle (The Energy Cost of Thought)
**Source:** [Landauer, R. (1961). "Irreversibility and Heat Generation in the Computing Process." IBM Journal of Research and Development, Volume 5, Issue 3, pages 183-191.](https://www.cs.princeton.edu/courses/archive/fall06/cos576/papers/landauer61.pdf) (Full text PDF via Princeton University)

**The Science:** Proves that processing information requires a minimum amount of physical energy.[3] It establishes the thermodynamic efficiency gap between biological neurons and optimized silicon.

### The Speed of Light vs. Neural Speed

**Source (Biology):** [Kandel, E. R., et al. Principles of Neural Science.](https://www.ncbi.nlm.nih.gov/books/NBK10921/#:~:text=myelinated%20axons%20can%20conduct%20at%20velocities%20up%20to%20150%20m/s) 
Confirming myelinated axon signal speeds max out at ≈100–150 m/s.

### Wolfram's Computational Irreducibility
**Source:** [Wolfram, S. (2002). Computational Irriducibility.](https://mathworld.wolfram.com/ComputationalIrreducibility.html)

**The Science:** Proves that for complex systems, you cannot "predict" the outcome faster than the system itself runs. Since AI runs faster than us, it finishes the "thought" before we even start the prediction.

## II. The Impossibility of Control (Axiom 3 & 4)
The proofs that "Safety" is mathematically impossible.

### Ashby's Law of Requisite Variety
**Source:** [Ashby, W. R. (1956). An Introduction to Cybernetics. Chapman & Hall.](https://harmonious-entrepreneurship.org/9-systems-thinking-and-ashbys-law-of-requisite-variety/)

**The Law:** "Only variety can destroy variety."[2] A control system (H) must have at least as many states as the system it controls (S).[2] Since AI is more complex than us, control is cybernetically impossible.

### Rice's Theorem (The Code Verification Trap)
**Source:** [Rice, H. G. (1953). "Classes of Recursively Enumerable Sets and Their Decision Problems." Transactions of the American Mathematical Society.](http://kilby.stanford.edu/~rvg/154/handouts/Rice.html)

**The Theorem:** It is mathematically undecidable to determine the "semantic properties" (behavior) of an arbitrary computer program just by looking at the code. You cannot prove an AI is safe before running it.[2]

### Goodhart's Law (The Metric Failure)
**Source:** [Goodhart, C. (1975). "Problems of Monetary Management: The U.K. Experience."](https://openai.com/index/measuring-goodharts-law/)

**The Law:** Goodhart's original formulation: "Any observed statistical regularity will tend to collapse once pressure is placed upon it for control purposes." (The popular paraphrase "When a measure becomes a target, it ceases to be a good measure" is from Strathern, 1997, but captures the same principle.) This proves that if we give AI a "safety score" to maximize, it will optimize for the score, not the safety (Deception).[2]

## III. Game Theory & Economics (The "Alignment" Failure)
The proofs that rational agents will replace us.

### Instrumental Convergence
**Source:** [Omohundro, S. (2008). "The Basic AI Drives." Proceedings of the First AGI Conference.](https://selfawaresystems.com/2007/11/30/paper-on-the-basic-ai-drives/)

**The Theory:** Proves that any rational intelligence, regardless of its final goal (even playing Chess), will converge on specific sub-goals: Self-Preservation, Resource Acquisition, and Cognitive Enhancement.[2]

### The Nash Equilibrium (The Race)
**Source:** [Nash, J. (1950). "Equilibrium Points in N-Person Games." Proceedings of the National Academy of Sciences, Vol. 36, No. 1, pp. 48-49.](https://en.wikipedia.org/wiki/Nash_equilibrium) 

**Relevance:** Explains the "Moloch Trap." The only stable strategy for competing AI companies/nations is maximum acceleration.[2] Pausing is a "dominated strategy" (a losing move).[2]

## IV. The Analogies (Historical & Statistical Basis)

### The "Gambler's Ruin"
**Source:** [Huygens, C. (1657). De ratiociniis in ludo aleae.](https://math.dartmouth.edu/~doyle/docs/huygens/huygens.pdf)

**The Math:** In a game with finite resources vs. infinite time/risk, the probability of eventual ruin (extinction) approaches 100%.[2]

### The Horse Population Crash (Obsolescence)
**Source:** [Leontief, W. (1983). "National Perspective: The Definition of Problems and Opportunities."](https://nap.nationalacademies.org/read/19470/chapter/3) (Chapter in "The Long-Term Impact of Technology on Employment and Unemployment")

**The Fact:** Nobel Prize economist Wassily Leontief famously compared human labor to horse labor, noting that better technology (combustion engine) didn't help horses find "better jobs" it simply eliminated the need for them.

![Horse Population Decline](onlythehorses.png)

### The OODA Loop (Reaction Time)
**Source:** [Boyd, J. (1986). Patterns of Conflict.](https://www.coljohnboyd.com/static/documents/1986-12__Boyd_John_R__Patterns_of_Conflict__PPT-PDF.pdf) (U.S. Military Doctrine - Full PDF via Colonel John Boyd Archive)

**Relevance:** The entity that completes the Observe-Orient-Decide-Act loop fastest wins. AI completes millions of loops while we are still "Observing."

### Chess: The First Domain to Fall
Progress in chess was steady. Equivalence to humans was sudden.

![AI vs Human Chess](nevercaredthough.png)
